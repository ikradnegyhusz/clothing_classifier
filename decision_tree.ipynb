{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = preprocessing.load_data(\"data/fashion_train.npy\")\n",
    "X_processed,pca = preprocessing.preprocess(X)\n",
    "# Now at this point we have the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(y, y_left, y_right):\n",
    "    p_left = len(y_left) / len(y)\n",
    "    p_right = len(y_right) / len(y)\n",
    "    \n",
    "    return gini_impurity(y) - (p_left * gini_impurity(y_left) + p_right * gini_impurity(y_right))\n",
    "\n",
    "def split_data(X, y, feature, threshold):\n",
    "    left_idx = X[:, feature] <= threshold\n",
    "    right_idx = X[:, feature] > threshold\n",
    "    return X[left_idx], y[left_idx], X[right_idx], y[right_idx]\n",
    "\n",
    "def gini_impurity(counts):\n",
    "    total = counts.sum()\n",
    "    prob = counts / total\n",
    "    return 1 - np.sum(prob**2)\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, 0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        n_samples, n_features = X.shape\n",
    "        if n_samples < self.min_samples_split or depth == self.max_depth or np.unique(y).size == 1:\n",
    "            return {'type': 'leaf', 'class': np.bincount(y).argmax()}\n",
    "\n",
    "        best_feature, best_threshold, best_gain = None, None, -np.inf\n",
    "        parent_impurity = gini_impurity(np.bincount(y))\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            sorted_idx = np.argsort(X[:, feature])\n",
    "            sorted_y = y[sorted_idx]\n",
    "            sorted_x = X[sorted_idx, feature]\n",
    "\n",
    "            # Computing thresholds\n",
    "            unique_values, first_indices = np.unique(sorted_x, return_index=True)\n",
    "            if len(first_indices) < 2:\n",
    "                continue  # No valid split possible\n",
    "\n",
    "            # Calculating left sizes and right sizes dynamically\n",
    "            sizes_left = first_indices[1:]  # sizes of left splits for each potential threshold\n",
    "            sizes_right = n_samples - sizes_left\n",
    "\n",
    "            # Ensure we only consider valid splits\n",
    "            valid_splits = np.where((sizes_left >= self.min_samples_split) & \n",
    "                                    (sizes_right >= self.min_samples_split))[0]\n",
    "            if valid_splits.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate impurities for these splits\n",
    "            cumulative_y_counts = np.array([np.bincount(sorted_y[:idx], minlength=np.max(y)+1) \n",
    "                                            for idx in sizes_left[valid_splits]])\n",
    "            left_impurities = np.array([gini_impurity(counts) for counts in cumulative_y_counts])\n",
    "            right_y_counts = np.bincount(sorted_y, minlength=np.max(y)+1) - cumulative_y_counts\n",
    "            right_impurities = np.array([gini_impurity(counts) for counts in right_y_counts])\n",
    "\n",
    "            # Calculate gains\n",
    "            left_sizes = sizes_left[valid_splits]\n",
    "            right_sizes = sizes_right[valid_splits]\n",
    "            gains = parent_impurity - (left_sizes / n_samples * left_impurities + \n",
    "                                       right_sizes / n_samples * right_impurities)\n",
    "\n",
    "            max_gain_idx = np.argmax(gains)\n",
    "            if gains[max_gain_idx] > best_gain:\n",
    "                best_gain = gains[max_gain_idx]\n",
    "                best_feature = feature\n",
    "                best_threshold = unique_values[valid_splits[max_gain_idx]]\n",
    "\n",
    "        if best_gain == -np.inf:\n",
    "            return {'type': 'leaf', 'class': np.bincount(y).argmax()}\n",
    "\n",
    "        left_idx = X[:, best_feature] <= best_threshold\n",
    "        right_idx = X[:, best_feature] > best_threshold\n",
    "        X_left, y_left = X[left_idx], y[left_idx]\n",
    "        X_right, y_right = X[right_idx], y[right_idx]\n",
    "        left_subtree = self._build_tree(X_left, y_left, depth + 1)\n",
    "        right_subtree = self._build_tree(X_right, y_right, depth + 1)\n",
    "\n",
    "        return {\n",
    "            'type': 'node',\n",
    "            'feature': best_feature,\n",
    "            'threshold': best_threshold,\n",
    "            'left': left_subtree,\n",
    "            'right': right_subtree\n",
    "        }\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([self._predict_one(x, self.tree) for x in X])\n",
    "        return predictions\n",
    "\n",
    "    def _predict_one(self, x, tree):\n",
    "        while tree['type'] != 'leaf':\n",
    "            if x[tree['feature']] <= tree['threshold']:\n",
    "                tree = tree['left']\n",
    "            else:\n",
    "                tree = tree['right']\n",
    "        return tree['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_scratch_model = DecisionTree(max_depth=3,min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Reference Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
